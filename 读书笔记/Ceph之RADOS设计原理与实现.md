# Ceph之RADOS设计原理与实现

## RADOS导论

Ceph三大核心应用

![image-20221109201741961](https://s2.loli.net/2022/11/09/qBec5iaH9lV2Uvm.png)

---

### 1.1 RADOS概述

​		一个RADOS集群由大量OSD（Object Store Device，对象存储设备）和少数几个Monitor组成。

​		OSD是个抽象概念，一般对应一个本地块设备（如一块磁盘或者一个RAID组等），在其工作周期内会占用一些CPU、内存、网络等物理资源，并依赖某个具体的本地对象存储引擎，来访问位于块设备上的数据。

​		基于高可靠设计的Monitor团体（quorum，本质上也是一个集群）则负责维护和分发集群的关键元数据，同时也是客户端与RADOS集群建立连接的桥梁——客户端通过咨询Monitor获得集群的关键元数据之后，就可以通过约定的方式（例如RBD、RGW、CephFS等）来访问RADOS集群.

![image-20221109202540260](https://s2.loli.net/2022/11/09/ERF3UdOvqZH4iQx.png)

​		为了去中心化、免除单点故障，RADOS使用一张紧凑的集群表对集群拓扑结构和数据映射规则进行描述。任何时刻，任何持有该表的合法客户端都可以独立地与位于任意位置的OSD直接通信。当集群拓扑结构发生变化时，RADOS确保这些变化能够及时地被Monitor捕获，并通过集群表高效传递至所有受影响的OSD和客户端，以保证对外提供不中断的业务访问。由于数据复制、故障检测和数据恢复都由每个OSD自动进行，因此即便存储容量上升至PB级别或者以上，系统也不会存在明显的调度和处理瓶颈。

---

### 1.2 存储池和PG

​		为了实现存储资源按需配置，RADOS对集群中的OSD进行池化管理。资源池（对存储系统而言，具体则是存储池）实际上是个虚拟概念，表示一组约束条件，例如可以针对存储池设计一组CRUSH规则，限制其只能使用某些规格相同的OSD，或者尽量将所有数据副本分布在物理上隔离的、不同的故障域；

​		为了实现不同存储池之间的策略隔离，RADOS并不是将任何应用程序数据一步到位地写入OSD的本地存储设备，而是引入了一个中间结构，称为PG（Placement Group），执行两次映射。
​		**第一次映射是静态的，负责将任意类型的客户端数据按照固定大小进行切割、编号后，作为伪随机哈希函数输入，均匀映射至每个PG，以实现负载均衡策略；第二次映射实现PG到OSD的映射，仍然采用伪随机哈希函数（以保证PG在OSD之间分布的均匀性），但是其输入除了全局唯一的PG身份标识之外，还引入了集群拓扑，并且使用CRUSH规则对映射过程进行调整，以帮助PG在不同OSD之间灵活迁移，进而实现数据可靠性、自动平衡等高级特性。最终，存储池以PG作为基本单位进行管理。**

![image-20221109204459894](https://s2.loli.net/2022/11/09/cO5miwFY1LvVNZ7.png)

​		为了维持扁平寻址空间，实际上要求PG拥有一个全集群唯一的身份标识——PGID。由于集群所有存储池都由Monitor统一管理，所以Monitor可以为每个存储池分配一个集群内唯一的存储池标识。基于此，我们只需要为存储池中的每个PG再分配一个存储池内唯一的编号即可。假定某个存储池的标识为1，创建此存储池时指定了256个PG，那么容易理解对应的PGID可以写成1.0，1.1，…，1.255这样的形式。

---

### 1.3 stable_mod和客户端寻址

​		Ceph通过C/S模式实现外部应用程序与RADOS集群之间的交互。任何时候，应用程序通过客户端访问集群时，首先由其客户端负责生成一个字符串形式的对象名，然后基于对象名计算得出一个32位哈希值。针对此哈希值，通过简单的数学运算，例如对存储池的PG数（pg_num）取模，可以得到一个PG在存储池内部的编号，加上对象本身已经记录了其归属存储池的唯一标识，最终可以找到负责承载该对象的PG。


$$
pg\_num > 2^n
$$


> 假定标识为1的存储池中的某个对象，经过计算后32位哈希值为0x4979FA12，并且该存储池的pg_num为256，则由：
> 0x4979FA12 mod 256 = 18
> 我们知道此对象由存储池内编号为18的PG负责承载，并且其完整的PGID为1.18。
>
> 一般而言，将某个对象映射至PG时，我们并不会使用全部的32位哈希值，因此会出现不同对象被映射至同一个PG的现象。我们很容易验证该存储池内哈希值如下的其他对象，通过模运算同样会被映射至PGID为1.18的PG之上。
> 0x4979FB12 mod 256 = 18
> 0x4979FC12 mod 256 = 18
> 0x4979FD12 mod 256 = 18
> …
>
> 可见，针对上面这个例子，我们仅仅使用了这个“全精度”32位哈希值的后8位。因此，如果pg_num可以写成2n的形式（例如这里256可以写成28，即是2的整数次幂），则每个对象执行PG映射时，其32位哈希值中仅有低n位是有意义的。进一步地，我们很容易验证此时归属于同一个PG的对象，其32位哈希值中低n位都是相同的。基于此，我们将2n-1称为pg_num的掩码，其中n为掩码的位数。

$$
2^n>pg\_num>2^{n-1}
$$



> 相反，如果pg_num不是2的整数次幂，即无法写成2n的形式，仍然假定此时其最高位为n（从1开始计数），则此时普通的取模操作无法保证“归属于某个PG的所有对象的低n位都相同”这个特性。例如，假定pg_num为12，此时n=4，容易验证如下输入经过模运算后结果一致，但是它们只有低2位是相同的。
> 0x00 mod 12 = 0
> 0x0C mod 12 = 0
> 0x18 mod 12 = 0
> 0x24 mod 12 = 0
> …
> 因此需要针对普通的取模操作加以改进，以保证针对不同输入，当计算结果相等时，维持“输入具有尽可能多的、相同的低位”这个相对有规律的特性。
>
> 一种改进的方案是使用掩码来替代取模操作。例如仍然假定pg_num对应的最高位为n，则其掩码为2n-1，需要将某个对象映射至PG时，直接执行hash &(2n-1)即可。但是这个改进方案仍然存在一个潜在问题：如果pg_num不是2的整数次幂，那么直接采用这种方式进行映射会产生空穴，即将某些对象映射到一些实际上并不存在的PG上。如图所示：这里pg_num为12，n=4，可见执行hash &(24-1)会产生0～15共计16种不同的结果。但是实际上编号为12～15的PG并不存在。
>
> ![image-20221110141524861](https://s2.loli.net/2022/11/10/TuOCxogtPmEIedN.png)
>
> 
>
> 因此需要进一步对上述改进方案进行修正。由n为pg_num的最高位，必然有：
> pg_num ≥ 2n-1
> 即[0，2n-1]内的PG必然都是存在的。于是可以通过hash &(2n-1-1)将那些实际上并不存在的PG重新映射到[0，2n-1]区间，如图所示:
>
> ![image-20221110142119958](https://s2.loli.net/2022/11/10/i39Yk6yAvJgTL8q.png)
>
> 修正后的效果等同于将这些空穴通过平移的方式重定向到前半个对称区间。

- **<font color="red">stable_num算法</font>**

![image-20221110144148806](https://s2.loli.net/2022/11/10/Uc7MCf6bxyVaQpS.png)

​		综上，无论pg_num是否为2的整数次幂，采用stable_mod都可以产生一个相对有规律的对象到PG的映射结果，这是PG分裂的一个重要理论基础。

---

### 1.4 PG分裂与集群扩容

> 如果分裂为4096个PG（此时n=12，对应的掩码为212-1=4095），则原来每个PG对应分裂成16个PG。仍以PGID为Y.D2的PG为例，通过简单计算可以得到这15个新增PG的PGID分别为：
> Y.1D2
> Y.2D2
> …
> Y.ED2
> Y.FD2
> 可见这些新的PG对应的对象分别存储于老PG的如下目录之下。
> ./2/D/1/
> ./2/D/2/
> …
> ./2/D/E/
> ./2/D/F/
> 此时可以不用移动对象（即文件），而是直接修改文件夹的归属，即可完成对象在新老PG之间的迁移。

## CRUSH算法

### 2.1 抽签算法

​		Ceph在设计之初被定位成用于管理大型分级存储网络的分布式文件系统。网络中的不同层级具有不同的故障容忍程度，因此也称为故障域。如图所示,展示了一个具有3个层级（机架、主机、磁盘）的Ceph集群。

<img src="https://s2.loli.net/2022/11/10/WhuoPVcO3HvU7Ak.png" alt="image-20221110163204466" style="zoom:80%;" />


$$
图2-1 具有3个层级的Ceph集群
$$
​	

​		在图2-1中，单个主机包含多个磁盘，每个机架包含多个主机，并采用独立的供电和网络交换系统，从而可以将整个集群以机架为单位划分为若干故障域。**为了实现高可靠性，实际上要求数据的多个副本分布在不同机架的主机磁盘之上。因此，CRUSH首先应该是一种基于层级的深度优先遍历算法。此外，上述层级结构中，每个层级的结构特征也存在差异，一般而言，越处于顶层的其结构变化的可能性越小，反之越处于底层的则其结构变化越频繁。**例如，大多数情况下一个Ceph集群自始至终只对应一个数据中心，但是主机或者磁盘数量随时间流逝则可能一直处于变化之中。**因此，从这个角度而言，CRUSH还应该允许针对不同的层级按照其特点设置不同的选择算法，从而实现全局和动态最优**。

​		Sage一共设计了4种不同的基本选择算法，这些算法是实现其他更复杂算法的基础，它们各自的优缺点如表2-1所示。


$$
表2-1 CRUSH基本选择算法
$$



|            | unique | list |   tree    | straw |
| :--------: | :----: | :--: | :-------: | :---: |
| 时间复杂度 |  O(1)  | O(N) | O(log(N)) | O(N)  |
|  添加元素  |   差   | 最好 |    好     | 最好  |
|  删除元素  |   差   |  差  |    好     | 最好  |

> ​	由表2-1可见,unique算法执行效率最高，但是抵御结构变化的能力最差；straw算法执行效率较低，但是抵御结构变化的能力最好；list和tree算法执行效率和抵御结构变化的能力介于unique与straw之间。如果综合考虑呈爆炸式增长的存储空间需求（导致需要添加元素）、在大型分布式存储系统中某些部件故障是常态（导致需要删除元素），以及愈发严苛的数据可靠性需求（导致需要将数据副本存储在更高级别的故障域中，例如不同的数据中心），那么针对任何层级采用straw算法都是一个不错的选择。事实上，这也是CRUSH算法的现状，在大多数将Ceph用于生产环境的案例中，除了straw算法之外，其他3种算法基本上形同虚设，因此我们将重点放在分析straw算法上。

​		顾名思义，**straw算法将所有元素比作吸管，针对指定输入，为每个元素随机地计算一个长度，最后从中选择长度最长的那个元素（吸管）作为输出。这个过程被形象地称为抽签（draw），元素的长度称为签长。**

​		显**然straw算法的关键在于如何计算签长。理论上，如果所有元素构成完全一致，那么只需要将指定输入和元素自身唯一编号作为哈希输入即可计算出对应元素的签长。因此，如果样本容量足够大，那么最终所有元素被选择的概率都是相等的，从而保证数据在不同元素之间均匀分布。**然而实际上，前期规划得再好的集群，其包含的存储设备随着时间的推移也会逐渐趋于异构化，例如，由于批次不同而导致的磁盘容量差异。

​		**显然，通常情况下，我们不应该对所有设备一视同仁，而是需要在CRUSH算法中引入一个额外的参数，称为权重，来体现设备之间的差异，让权重大（对应容量大）的设备分担更多的数据，权重小（对应容量小）的设备分担更少的数据，从而使得数据在异构存储网络中也能合理地分布。**

​		**将上述理论应用于straw算法，则可以通过使用权重对签长的计算过程进行调整来实现，即我们总是倾向于让权重大的元素有较大的概率获得更大的签长，从而在每次抽签中更容易胜出**。因此，引入权重之后straw算法的执行结果将取决于3个因素：固定输入、元素编号和元素权重。这其中，元素编号起的是随机种子的作用，所以针对固定输入，straw算法实际上只受元素权重的影响。进一步地，如果每个元素的签长只与自身权重相关，则可以证明此时straw算法对于添加元素和删除元素的处理都是最优的。我们以添加元素为例进行论证。

> 1）假定当前集合中一共包含n个元素：
> (e1，e2，…，en)
> 2）向集合中添加新元素en+1：
> (e1，e2，…，en，en+1)
> 3）针对任意输入x，加入en+1之前，分别计算每个元素签长并假定其中最大值为dmax：
> (d1，d2，…，dn)
> 4）因为新元素en+1的签长计算只与自身编号及自身权重相关，所以可以使用x独立计算其签长（同时其他元素的签长不受en+1加入的影响），假定为dn+1；
> 5）又因为straw算法总是选择最大的签长作为最终结果，所以：
> 如果dn+1>dmax，那么x将被重新映射至新元素en+1；反之，对x的已有映射结果无任何影响。
>
> ​	可见，添加一个元素，straw算法会随机地将一些原有元素中的数据重新映射至新加入的元素之中。同理，删除一个元素，straw算法会将该元素中全部数据随机地重新映射至其他元素之中。因此无论添加或者删除元素，都不会导致数据在除被添加或者删除之外的两个元素（即不相干的元素）之间进行迁移。

***

### 2.2 CRUSH算法详解

​		CRUSH基于上述基本选择算法完成数据映射，这个过程是受控的并且高度依赖于集群的拓扑描述——cluster map。不同的数据分布策略通过制定不同的placement rule来实现。placement rule实际上是一组包括最大副本数、故障（容灾）级别等在内的自定义约束条件，例如针对图2-1所示的集群，我们可以通过一条placement rule将互为镜像的3个数

> ​	例如针对图2-1所示的集群，我们可以通过一条placement rule将互为镜像的3个数据副本（这也是Ceph的默认数据备份策略）分别写入位于不同机架的主机磁盘之上，以避免因为某个机架掉电而导致业务中断。

​		针对指定输入x，CRUSH将输出一个包含n个不同目标存储对象（例如磁盘）的集合。CRUSH的计算过程中仅仅使用x、cluster map和placement rule作为哈希函数输入，因此如果cluster map不发生变化（一般而言placement rule不会轻易变化），那么结果就是确定的；同时由于使用的哈希函数是伪随机的，所以CRUSH选择每个目标存储对象的概率相对独立（然而我们在后面将会看到，受控的副本策略改变了这种独立性），从而可以保证数据在整个集群之间均匀分布。

#### 2.2.1 集群的层级化描述-cluster map

​		cluster map是Ceph集群拓扑结构的逻辑描述形式。考虑到生产环境中集群通常具有形如“数据中心→机架→主机→磁盘”（参考图2-1）这样的层级拓扑，所以cluster map使用树这种数据结构来实现：每个叶子节点都是真实的最小物理存储设备（例如磁盘），称为device；所有中间节点统称为bucket，每个bucket可以是一些devices的集合，也可以是低一级的buckets集合；根节点称为root，是整个集群的入口。每个节点绑定一种类型，表示其在集群中所处的层级，也可以作为故障域，除此之外还包含一个集群唯一的数字标识。根节点与中间节点的数字标识都是负值，只有叶子节点，也就是device才拥有非负的数字标识，表明其是承载数据的真实设备。节点的权重属性用于对CRUSH的选择过程进行调整，使得数据分布更加合理。父节点权重是其所有孩子节点的权重之和。

表2-2列举了cluster map中一些常见的节点（层级）类型。、


$$
表2-2\ \ \ \ cluster\ \ map常见的节点类型
$$



| 类型ID | 类型名称 | 类型ID |  类型名称  |
| :----: | :------: | :----: | :--------: |
|   0    |   osd    |   6    |    pod     |
|   1    |   host   |   7    |    room    |
|   2    | chassis  |   8    | datacenter |
|   3    |   rack   |   9    |   region   |
|   4    |   row    |   10   |    root    |
|   5    |   pdu    |        |            |

> ​		需要注意的是，这里并非强调每个Ceph集群都一定要划分为如表2-2所示的11个层级，并且每种层级类型的名称必须固定不变，而是层级可以根据实际情况进行裁剪，名称也可以按照自身习惯进行修改。假定所有磁盘规格一致（这样每个磁盘的权重一致），我们可以绘制图2-1所示集群的cluster map，如图2-2所示。

<img src="https://s2.loli.net/2022/11/13/OpfZw7eBGRgtXn9.png" alt="image-20221113183518274" style="zoom:80%;" />


$$
图2-2\ \ \ \ 图2-1所示集群的cluster map描述
$$



> ​		实现上，类似图2-2中这种树状的层级关系在cluster map中可以通过一张二维映射表建立。
> ​		<bucket, items>
> ​		树中每个节点都是一个bucket（device也被抽象成为一种bucket类型），每个bucket都只保存自身所有直接孩子的编号。当bucket类型为device（对应图2-2中的osd）时，容易知道，此时其对应的items列表为空，表明bucket实际上是叶子节点。

#### 2.2.2 数据分布策略-placement rule

​		使用cluster map建立对应集群的拓扑结构描述之后，可以定义placement rule来完成数据映射。
​		每条placement rule可以包含多个操作，这些操作有以下3种类型。
​		1）take：从cluster map选择指定编号的bucket（即某个特定bucket），并以此作为后续步骤的输入。例如，系统默认的placement rule总是以cluster map中的root节点作为输入开始执行的。
​		2）select：从输入的bucket中随机选择指定类型和数量的条目（items）。Ceph当前支持两种备份策略，多副本和纠删码，相应的有两种select算法，firstn和indep。实现上两者都是采用深度优先遍历算法，并无显著不同，主要区别在于纠删码要求结果是有序的，因此，如果无法得到满足指定数量（例如4）的输出，那么firstn会返回形如[1，2，4]这样的结果，而indep会返回形如[1，2，CRUSH_ITEM_NONE，4]这样的结果，即indep总是返回要求数量的条目，如果对应的条目不存在（即选不出来），则使用空穴进行填充。select执行过程中，如果选中的条目故障、过载或者与其他之前已经被选中的条目冲突，都会触发select重新执行，因此需要指定最大尝试次数，防止select陷入死循环。
​		3）emit：输出选择结果。
​		可见，placement rule中真正起决定性作用的是select操作。
​		为了简化placement rule配置，select操作也支持故障域模式。以firstn为例，如果为故障域模式，那么firstn将返回指定数量的叶子设备，并保证这些叶子设备位于不同的、指定类型的故障域之下。因此，在故障域模式下，一条最简单的placement rule可以只包含如下3个操作：
​		take(root)
​		select(replicas, type)
​		emit(void)
​		上述select操作中的type为想要设置的故障域类型，例如设置为rack，则select将保证选出的所有副本都位于不同机架的主机磁盘之上；也可以设置为host，那么select只保证选出的所有副本都位于不同主机的磁盘之上。
​		图2-3以firstn为例，展示了select从指定的bucket当中查找指定数量条目的过程。
​		图2-3中几个关键处理步骤补充说明如下：
​		1）如何从bucket下选择一个条目（item）？
​		构建集群的cluster map时，通过分析每种类型的bucket特点，可以为其指定一种合适的选择算法（例如straw2），用于从对应的bucket中选择一个条目。因此从bucket选择条目的过程实际上就是执行设定的选择算法。这个选择算法的执行结果取决于两个因素：一是输入对象的特征标识符x，二是随机因子r（r实际上是哈希函数的种子）。因为x固定不变，所以如果选择失败，那么在后续重试的过程中需要对r进行调整，以尽可能输出不同的结果。目前r由待选择的副本编号和当前的尝试次数共同决定。
​		为了防止陷入死循环，需要对选择每个副本过程中的尝试次数进行限制，这个限制称为全局尝试次数（choose_total_tries）；同时由于在故障域模式下会产生递归调用，所以还需要限制产生递归调用时作为下一级输入的全局尝试次数。由于这个限制会导致递归调用时的全局尝试次数成倍增长，实现上采用一个布尔变量（chooseleaf_descend_once）进行控制，如果为真，则在产生递归调用时下一级被调用者至多重试一次，反之则下一级被调用者不进行重试，由调用者自身重试。为了降低冲突概率（如前，每次尽量使用不同的随机因子r可以减少冲突概率），也可以使用当前的重试次数（或者其2N-1倍，这里的N由chooseleaf_vary_r参数决定）对递归调用时的随机因子r再次进行调整，这样产生递归调用时，其初始随机因子r将取决于待选择的副本编号和调用者传入的随机因子（称为parent_r）。

![image-20221113185051031](https://s2.loli.net/2022/11/13/iZPBFjOaEUDh9Hm.png)


$$
图2-3\ \ \ \ 基于firstn的select执行过程
$$


​		值得一提的是，Jewel版本之前，故障域模式下作为递归调用时所使用的副本编号是固定的，例如调用者当前正在选择第2个副本，那么执行递归调用时的起始副本编号也将是2。按照上面的分析，副本编号会作为输入参数之一对递归调用时的初始随机因子r产生影响，有的用户反馈，这在OSD失效时会触发不必要的数据（PG）迁移，因此在Jewel版本之后，故障域模式下会对递归调用的起始副本独立编号（这个操作受chooseleaf_stable控制），以进一步降低两次调用之间的相关性。	

​		由于选择的过程是执行深度优先遍历，在老的CRUSH实现中，如果对应集群的层次较多，并且在中间某个层次的bucket下由于冲突而选择条目失败，那么可以在当前的bucket下直接进行重试，而不用每次回归到初始输入的bucket之下重新开始重试，这样可以稍微提升算法的执行效率，此时同样需要对这个局部重试过程中的重试次数进行限制，称为局部重试次数（choose_local_retries）。此外，由于进入这种模式的直接原因是bucket自带选择算法冲突概率较高（即使用不同的r作为输入反复选中同一个条目），所以针对这种模式还设计了一种后备选择算法。这种后备选择算法的基本原理是：将对应bucket下的所有条目进行随机重排，只要输入x不变，那么随着r变化，算法会不停地记录前面已经被选择过的条目，并从本次选择的候选条目中排除，从而能够有效地降低冲突概率，保证最终能够成功选中一个不再冲突的条目。切换至后备选择算法需要冲突次数达到某个阈值，其主要由当前bucket的规模决定（原实现中要求冲突次数至少大于当前bucket下条目数的一半）。当然切换至后备选择算法时，也可以再次限制启用后备选择算法进行重试的次数（choose_local_fallback_retries）。上述过程因为对整个CRUSH的执行过程进行了大量人工干预从而严重损伤了CRUSH的伪随机性（即公平性），所以会导致严重的数据均衡问题，因此在Ceph的第一个正式发行版Argonaut之后即被废弃，不再建议启用。

​		表2-3汇总了如上分析的、所有影响CRUSH执行的可调参数（表中的默认值和最优值针对Jewel版本而言）。


$$
表2-3\ \ \ \ CRUSH可调参数
$$





|          参数名称           | 默认值/最优值 |                             说明                             |
| :-------------------------: | :-----------: | :----------------------------------------------------------: |
|     choose_local_tries      |      0/0      |                      已废弃，不建议调整                      |
| choose_local_fallback_tries |      0/0      |                      已废弃，不建议调整                      |
|     choose_total_tries      |     50/50     | 如果集群比较大，层次比较多，或者每个主机下的磁盘数量比较少，可能会导致CRUSH无法选出足够的OSD完成所有副本数映射，此时可以通过设置更大的choose_total_tries加以解决 |
|   chooseleaf_descent_once   |      1/1      | 控制故障域模式下产生递归调用时的重试次数<br />至多产生一次递归调用，递归时如果此表示位置位，至多重试一次。<br />不建议进行调整 |
|      chooseleaf_vary_r      |      1/1      |                        不建议进行调整                        |
|      chooseleaf_stable      |      1/1      |                        不建议进行调整                        |
|     straw_calc_version      |      1/1      | 用于对straw类型bucket下的条目权重计算过程进行校正。由于straw算法已经被废弃，所以本参数对于新建集群无影响 |

2）冲突

​		冲突指选中的条目已经存在于输出条目列表之中。

3）OSD过载（或失效）
		虽然哈希以及由哈希派生出来的CRUSH算法从理论上能够保证数据在所有磁盘之间均匀分布，但是实际上，以下因素：

- 集群规模较小，集群整体容量有限，导致集群PG总数有限，亦即CRUSH输入的样本容量不够。
- CRUSH本身的缺陷。CRUSH的基本选择算法中，以straw2为例，每次选择都是计算单个条目被选中的独立概率，但是CRUSH所要求的副本策略使得针对同一个输入、多个副本之间的选择变成了计算条件概率（我们需要保证副本位于不同故障域中的OSD之上），所以从原理上CRUSH就无法处理好多副本模式下的副本均匀分布问题。

​       都会导致在真实的Ceph集群、特别是异构集群中，出现大量磁盘数据分布悬殊（这里指每个磁盘已用空间所占的百分比）的情况，因此需要对CRUSH计算结果进行人工调整。这个调整同样是基于权重进行的，即针对每个叶子设备（OSD），除了由其基于容量计算得来的真实权重（weight）之外，Ceph还为其设置了一个额外的权重，称为reweight。算法正常选中一个OSD后，最后还将基于此reweight对该OSD进行一次过载测试，如果测试失败，则仍将拒绝选择该条目，这个过程如图2-4所示。

<img src="https://s2.loli.net/2022/11/13/TcpCWRdj91agEFD.png" alt="image-20221113193150546" style="zoom:80%;" />


$$
图2-4 \ \ \ \ 过载测试
$$


​		由图2-4可见，对应OSD的reweight调整得越高，那么通过测试的概率越高（例如手动设置某个OSD的reweight为0x10000，那么通过测试的概率是100％），反之则通过测试的概率越低。因此实际应用中，通过降低过载OSD或者（和）增加低负载OSD的reweight，都可以触发数据在OSD之间重新分布，从而使得数据分布更加合理。
​		引入过载测试的另一个好处在于可以对OSD暂时失效和OSD被永久删除的场景进行区分。区分这两者的意义在于：如果OSD暂时失效（例如对应的磁盘被拔出超过一定时间，Ceph会将其设置为out），可以通过将其reweight调整为0，从而利用过载测试将其从候选条目中淘汰，进而将其承载的数据迁移至其他OSD，这样后续该OSD正常回归时，将其reweight重新调整为0x10000即可将原来归属于该OSD的数据再次迁回，而迁回过程中只需要同步该OSD离线期间产生的新数据即可，亦即只需要进行增量同步；相反，如果是删除OSD，此时会同步将其从对应的bucket条目中删除，这样即便该OSD后续被重新添加回集群，由于其在cluster map中的唯一编号可能已经发生了变化，所以也可能承载与之前完全不同的数据。
​		初始时，Ceph将每个OSD的reweight都设置为0x10000，因此上述过载测试对CRUSH的最终选择结果不会产生任何影响。